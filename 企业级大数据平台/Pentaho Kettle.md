# Pentaho Kettle
Kettle是一款由纯Java语言开发的免费开源的ETL工具,ETL即是Extract-Transform-Load的缩写,
用来描述将数据从来源端通过提取(Extract)、转换(Transform)、加载(Load)到目标端的过程, 通常用于数据清洗、数据迁移等.
## 安装和部署
Github地址: https://github.com/pentaho/pentaho-kettle

1. Jdk安装部署
2. Kettle 安装部署，目前需要在Github下载源码手动编译

编译完成后,我们需要关注Kettle的几个关键目录和文件

- Spoon:这是Kettle为我们提供的Spoon图形化界面启动程序,bat是在Windows环境下运行,sh则是在 类Unix环境中运行，用于创建/编辑作业或者转换
- Pan:我们通过Spoon创建了转换或者作业后,如果是保存在本地磁盘的话,会生成响应的文件,转换文件是以.ktr结尾，而Pan是转换的命令行执行程序,
- Kitchen:作业文件以.kjb结尾,而Kitchen是作业的命令行执行程序
- Carte:轻量级的HTTP服务器(依托于Jetty实现),后台的方式运行,监听HTTP请求来运行一个作业.Carte也可用于分布式和协调跨机器执行作业,即Kettle集群方式.
- lib:该目录是Kettle依赖的第三方Jar包目录,如果我们在使用Kettle进行数据库导入的话,此时如果Kettle中没有该数据库的驱动Jar包时,我们需要将从网站上下载的驱动Jar放到该lib目录下,然后重启程序进行调试,否则会报错(驱动类不存在)
- Encr:上面我们所说的创建数据库连接时,我们需要输入密码,但是我们的密码不能是明文,Encr工具为我们提供加密服务

## 核心概念
Kettle中两个核心的组件服务：转换和作业

- 转换：转换(transformation)是ETL解决方案中最主要的部分,它负责抽取、转换、加载各个阶段的数据操作处理,转换包括一个或多个步骤,
如读取文件、请求REST接口、插入数据、过滤数据等等,各个步骤之间通过Hop连接,Hop代表的是一个单向的数据流通道。通过:文件 -> 新建 -> 转换用以创建转换
- 作业：作业(job)通常是一组转换的集合,比如一个条件的判断,参数的轮训执行转换,因为转换的执行只能执行一次,
遇上分页接口的转换我们需要借助于作业的方式轮训执行转换以阶级数据的抽取工作,在作业中可以对转换的执行成功发送邮件服务等,通过:文件 -> 新建 -> 作业用以创建作业

