# Pentaho Kettle
Kettle是一款由纯Java语言开发的免费开源的ETL工具,ETL即是Extract-Transform-Load的缩写,
用来描述将数据从来源端通过提取(Extract)、转换(Transform)、加载(Load)到目标端的过程, 通常用于数据清洗、数据迁移等.

## 安装和部署
Github地址: https://github.com/pentaho/pentaho-kettle

1. JDK安装部署
2. Kettle 安装部署，目前需要在Github下载源码手动编译

编译完成后,我们需要关注Kettle的几个关键目录和文件

- Spoon：图形界面工具，快速设计和维护复杂的ETL工作流。
- Kitchen：运行作业的命令行工具。
- Pan：运行转换的命令行工具。
- Carte：轻量级的（大概1MB）Web服务器，用来远程执行转换或作业。一个运行有Carte进程的机器可以作为从服务器，从服务器是Kettle集群的一部分。
- lib:该目录是Kettle依赖的第三方jar包目录,如果我们在使用Kettle进行数据库导入的话,此时如果Kettle中没有该数据库的驱动jar包时,我们需要将从网站上下载的驱动jar放到该lib目录下,然后重启程序进行调试,否则会报错(驱动类不存在)
- Encr:上面我们所说的创建数据库连接时,我们需要输入密码,但是我们的密码不能是明文,Encr工具为我们提供加密服务

## 核心概念
Kettle中两个核心的组件服务：转换和作业

- 转换：转换(transformation)是ETL解决方案中最主要的部分,它负责抽取、转换、加载各个阶段的数据操作处理,转换包括一个或多个步骤,
如读取文件、请求REST接口、插入数据、过滤数据等等,各个步骤之间通过Hop连接,Hop代表的是一个单向的数据流通道。通过:文件 => 新建 => 转换用以创建转换
- 作业：作业(job)通常是一组转换的集合,比如一个条件的判断,参数的轮训执行转换,因为转换的执行只能执行一次,
遇上分页接口的转换我们需要借助于作业的方式轮训执行转换以阶级数据的抽取工作,在作业中可以对转换的执行成功发送邮件服务等,通过:文件 => 新建 => 作业用以创建作业

## 数据库连接




