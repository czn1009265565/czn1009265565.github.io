# 摘要链

解决的问题: 自动化地、高效地处理超出大型语言模型单次上下文窗口长度的文档摘要任务

功能: 提供了三种策略

- Stuff: 将整个文档（或所有文档）的全部内容，一次性填充到LLM的上下文窗口（Context Window）中，然后要求模型生成一个总结
- Map Reduce: 独立处理每个文本块，并生成子摘要，然后将所有子摘要归纳、合并成一个最终的、连贯的总结
- Refine: 依次处理每个文本块，并在已有摘要的基础上，不断地用新文本块的信息来优化和丰富摘要

## Stuff

### 工作流程

1. 连接所有文本：将所有需要总结的文本块（chunks）简单地拼接在一起
2. 单次LLM调用：将拼接后的长文本和一个预设的提示模板（例如：“请总结以下文本：{text}”）一起发送给LLM
3. 生成总结：LLM基于接收到的全部信息，直接输出最终的摘要

### 优缺点及适用场景

简单高效，保持最佳连贯性，但受限于上下文长度，适用于总结篇幅较短的文档，如新闻文章、博客帖子、短报告等。


### 实例

```python
from langchain import PromptTemplate
from langchain.document_loaders import  PyPDFLoader
from langchain.chains.summarize import load_summarize_chain

# 文档加载
loader = PyPDFLoader("loader.pdf")
docs = loader.load()


# 3. 定义自定义提示模板 注意: {text} 是必须保留的占位符，链会用它来填充文档内容
custom_prompt_template = """请执行以下任务：
1. 用中文为以下文本撰写一个简洁的摘要。
2. 摘要需要突出三个最关键的点。
3. 摘要长度不超过150字。

文本：
{text}

中文摘要："""
PROMPT = PromptTemplate(template=custom_prompt_template, input_variables=["text"])

chain = load_summarize_chain(
    llm,
    chain_type="stuff", # 指定使用stuff方法
    prompt=PROMPT,      # 可选: 使用自定义提示模板
    verbose=True        # 可选: 查看执行过程
)

summary_result = chain.run(docs)
print(summary_result)
```

## Map Reduce

### 工作流程

1. 文档分割: 使用文本分割器将原始文档分割成多个块
2. Map阶段: 为每个文本块执行摘要操作（可以并行处理，以提高速度）。提示词示例："对以下文字做简洁的总结:{text} 简洁的总结:"
3. Reduce阶段：将所有子摘要组合在一起，执行归纳操作。提示词示例："以下是一个摘要集合:{doc_summaries} 将上述摘要与所有关键细节进行总结。总结:"

### 优缺点及适用场景

突破上下文长度限制，可并行处理，但可能丢失全局上下文，依赖分割质量（在一个句子的中间或一个论点的核心处切断，会严重影响摘要质量），LLM调用次数多

适用于总结非常长的文档，如书籍、长篇论文、完整的企业年报等


### 实例

```python
from langchain.prompts import PromptTemplate
from langchain.document_loaders import PyPDFLoader
from langchain.chains.summarize import load_summarize_chain

#load pdf
loader = PyPDFLoader("loader.pdf")
docs = loader.load()


# Map阶段：处理每个分块
map_template = """请总结以下文本片段的核心内容：
{text}
核心内容总结："""
map_prompt = PromptTemplate(template=map_template, input_variables=["text"])

# Reduce阶段：合并所有总结
reduce_template = """请基于以下多个总结片段，生成一个连贯、全面的总体总结：
{text}
总体总结："""
reduce_prompt = PromptTemplate(template=reduce_template, input_variables=["text"])

chain = load_summarize_chain(
    llm,
    chain_type="map_reduce",
    map_prompt=map_prompt,
    combine_prompt=reduce_prompt,
    verbose=True
)

result = chain.run(docs)
print(result)
```


## Refine

### 工作流程

1. 文档分割：将文档分割成按顺序排列的文本块
2. 处理第一个块: 对第一个文本块生成一个初始摘要，提示词示例: "请总结以下内容的主要观点：{text}"
3. 迭代处理后续块: 对于第二个及之后的每一个文本块，将当前已有的摘要和新的文本块一起提供给LLM，指示它基于新信息来优化现有摘要。提示词示例: "现有总结：{existing_answer} 新增内容：{text} 请结合新内容完善总结，保持逻辑连贯性"

### 优缺点及适用场景
生成质量高，更好地把握叙述流，但无法并行处理，LLM调用次数多，可能存在错误累积。

### 实例

```python
from langchain import PromptTemplate
from langchain.document_loaders import  PyPDFLoader
from langchain.chains.summarize import load_summarize_chain

# 文档加载
loader = PyPDFLoader("loader.pdf")
docs = loader.load()

question_template = "请总结以下内容的主要观点：{text}"
question_prompt = PromptTemplate(
    template=question_template,
    input_variables=["text"]
)

# 迭代优化提示
refine_template = "现有总结：{existing_answer} 新增内容：{text}请结合新内容完善总结，保持逻辑连贯性"
refine_prompt = PromptTemplate(
    template=refine_template,
    input_variables=["existing_answer", "text"]
)

chain = load_summarize_chain(
    llm,
    chain_type="refine",
    question_prompt=question_prompt,
    refine_prompt=refine_prompt,
    verbose=True
)
summary_result = chain.run(docs)
print(summary_result)
```