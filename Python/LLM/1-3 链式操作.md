# 链式操作

## 顺序链(Sequential Chains)
顺序链是最基本的链式操作，按照预定义的顺序依次执行多个任务

类型：
- 简单顺序链（SimpleSequentialChain）：前一个链的输出直接作为后一个链的输入
- 常规顺序链（SequentialChain）：可以处理多个输入和输出，更灵活

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate


llm = ChatOpenAI(
    api_key="sk-",
    base_url="https://api.deepseek.com/v1",
    model="deepseek-chat"
)

# 定义第一个链：文本总结
summary_template = """请总结以下文本：{text}"""
summary_prompt = PromptTemplate.from_template(summary_template)
summary_chain = summary_prompt | llm

# 定义第二个链：情感分析
sentiment_template = """分析以下文本的情感倾向：{summary}"""
sentiment_prompt = PromptTemplate.from_template(sentiment_template)
sentiment_chain = sentiment_prompt | llm

# 创建顺序链
overall_chain = summary_chain | sentiment_chain

# 执行
result = overall_chain.invoke({"text":"今天整个城市被雾霾笼罩"})
print(result)
```


## 路由链(Router Chains)
路由链根据输入内容动态选择要执行的子链，适用于多任务场景

工作原理：
- 使用一个路由器链来判断输入应该路由到哪个目标链
- 基于输入内容的特点进行智能分发

```python
from langchain_classic.chains.llm import LLMChain
from langchain_classic.chains.router import MultiRouteChain, LLMRouterChain
from langchain_classic.chains.router.llm_router import RouterOutputParser
from langchain_classic.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# 初始化LLM
llm = ChatOpenAI(
    api_key="sk-",
    base_url="https://api.deepseek.com/v1",
    model="deepseek-chat"
)
prompt_infos = [
    {"name": "技术问题链", "description": "适合回答技术类问题", "template": "你是一个技术专家，请回答：{input}"},
    {"name": "通用问题链", "description": "适合回答一般问题", "template": "你是一个通用专家，请回答：{input}"},
]

# 1. 定义子链
destination_chains = { i.get('name') : LLMChain(llm=llm, prompt=PromptTemplate.from_template(i['template'])) for i in prompt_infos}
general_chain = destination_chains['通用问题链']

# 2. 定义路由链
router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(
    destinations="\n".join([f"{p['name']}: {p['description']}" for p in prompt_infos])
)
route_prompt = PromptTemplate(
    template=router_template,
    input_variables=["input"],
    output_parser=RouterOutputParser()
)

router_chain = MultiRouteChain(
    router_chain=LLMRouterChain.from_llm(llm, route_prompt),
    destination_chains=destination_chains,
    default_chain=general_chain
)

# 使用
result = router_chain.invoke({"input":"Python内存泄漏怎么解决？"})
print(result)
```

## 条件链

条件链根据特定条件决定执行路径，实现分支逻辑。

实现方式：  
- 使用TransformChain进行条件判断
- 基于判断结果选择不同的执行路径

```python
from langchain_classic.chains.base import Chain
from langchain_classic.chains.llm import LLMChain
from langchain_classic.chains.transform import TransformChain
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# 初始化LLM
llm = ChatOpenAI(
    api_key="sk-",
    base_url="https://api.deepseek.com/v1",
    model="deepseek-chat"
)

# 条件判断函数
def condition_function(inputs):
    text = inputs["text"]
    # 简单的关键词判断条件
    if "紧急" in text or "重要" in text:
        return {"condition": "high_priority"}
    else:
        return {"condition": "normal_priority"}

# 创建条件判断链
condition_chain = TransformChain(
    input_variables=["text"],
    output_variables=["condition"],
    transform=condition_function
)

# 高优先级处理链
high_priority_template = """【紧急处理】请优先处理以下内容：{text}"""
high_priority_prompt = PromptTemplate(
    template=high_priority_template,
    input_variables=["text"]
)
high_priority_chain = LLMChain(llm=llm, prompt=high_priority_prompt)

# 普通优先级处理链
normal_priority_template = """处理以下内容：{text}"""
normal_priority_prompt = PromptTemplate(
    template=normal_priority_template,
    input_variables=["text"]
)
normal_priority_chain = LLMChain(llm=llm, prompt=normal_priority_prompt)

# 自定义条件链
class ConditionalChain(Chain):
    @property
    def input_keys(self):
        return ["text"]

    @property
    def output_keys(self):
        return ["result"]

    def _call(self, inputs):
        # 先进行条件判断
        condition_result = condition_chain(inputs)
        condition = condition_result["condition"]

        # 根据条件选择执行路径
        if condition == "high_priority":
            result = high_priority_chain(inputs)
        else:
            result = normal_priority_chain(inputs)

        return {"result": result["text"]}

# 使用条件链
conditional_chain = ConditionalChain()
result1 = conditional_chain({"text": "这是一个紧急问题需要处理"})
result2 = conditional_chain({"text": "这是一般性问题"})
print(result1)
print(result2)
```